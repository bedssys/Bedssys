PERFORMANCE ON TRAIN SET:             Batch Loss = 1.513102650642395, Accuracy = 0.5920151472091675
PERFORMANCE ON TEST SET:             Batch Loss = 1.546020746231079, Accuracy = 0.5816797614097595

The accuracy is dropping to 50% during retraining, when it was around 70-80% from last session.
This might be because of the learning rate.

At start        : 0.005
End of training : 0.00015

Thus a single iteration of first stage = 33x after 1024 iteration.

[After testing the reduced initial learning rate]
Yup, while it was low at first, it jumped straight up.
So, you must reconfigure the learning rate, which require you to restart the kernel.

Also for some reason, inferencing the 1024e data shows 10% accuracy on TRAIN & TEST set (not 70% as I claimed),
so the initial learning rate during retrainig doesn't really affect much and the model is still trained.